{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "## New York Time Articles\n",
    "\n",
    "### Goal of this notebook\n",
    "\n",
    "> Extract NYT articles from previous 18 months in order to create a sample dataset which will be mined on future notebooks.\n",
    "\n",
    "### Context\n",
    "\n",
    "> I have coded `src.extracting.NYTScrapper` as a wrapper for NYT API so the extraction could be done considering desks (or subjects) and time ranges. This makes it easier to interact with the API and enables future custumized sample generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from src.extracting.NYTScrapper import extract_desk_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I've selected a few subjects (desks) according to my interests and data volume in order to assure a minimal statistical representation (too few articles of a given theme may jeopardize the analysis). My idea now is to create a Text Classifier based on these labels, so in an application it could recommend the specific subject of an article based on its text and avoid misplacing articles on the wrong section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "desks = [\n",
    "    \"Arts\",\n",
    "    \"Business\",\n",
    "    \"Environment\",\n",
    "    \"Financial\",\n",
    "    \"Foreign\",\n",
    "    \"Health\",\n",
    "    \"Movies\",\n",
    "    \"Politics\",\n",
    "    \"Science\",\n",
    "    \"Sports\",\n",
    "    \"Technology\",\n",
    "    \"U.S.\",\n",
    "    \"World\",\n",
    "]\n",
    "begin_date = datetime.datetime.today()-datetime.timedelta(days=540)\n",
    "end_date = datetime.datetime.today()-datetime.timedelta(days=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts article data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_articles = extract_desk_articles(desks, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles succesfully extracted to `LOCAL_RAW_DATA_PATH` in several csv files (one per request)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
