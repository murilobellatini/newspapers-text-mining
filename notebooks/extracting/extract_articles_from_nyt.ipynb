{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "## New York Time Articles\n",
    "\n",
    "### Goal of this notebook\n",
    "\n",
    "> Extract NYT articles from previous 3 months in order to create a sample dataset which will be mined on future notebooks.\n",
    "\n",
    "### Context\n",
    "\n",
    "> I have coded `src.extracting.NYTScrapper` as a wrapper for NYT API so the extraction could be done considering desks (or subjects) and time ranges. This makes it easier to interact with the API and enables future custumized sample generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from src.extracting.NYTScrapper import get_desk_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines parameters for sample.\n",
    "\n",
    "Here I've selected a few subjects (desks) according to my interests and data volume. My idea now is to create a Text Classifier based on these labels, so in an application it could recommend the specific subject of an article and avoid misplacing articles on the wrong section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "desks = [\n",
    "    \"Arts\",\n",
    "    \"Business\",\n",
    "    \"Environment\",\n",
    "    \"Financial\",\n",
    "    \"Foreign\",\n",
    "    \"Health\",\n",
    "    \"Movies\",\n",
    "    \"Politics\",\n",
    "    \"Science\",\n",
    "    \"Sports\",\n",
    "    \"Technology\",\n",
    "    \"U.S.\",\n",
    "    \"World\",\n",
    "]\n",
    "begin_date = datetime.datetime.today()-datetime.timedelta(days=90)\n",
    "end_date = datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts article data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/90 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "output_articles = get_desk_articles(desks, begin_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles succesfully extracted and stored in `csv` format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
