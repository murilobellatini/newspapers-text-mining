{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "## New York Time Articles\n",
    "\n",
    "### Goal of this notebook\n",
    "\n",
    "> Export raw data extracted from NYT API to two consolidated DataFrames, `nyt-articles-consolidated.csv` and `nyt-articles-consolidated-exploded.csv`\n",
    "> * `nyt-articles-consolidated.csv`: Full DataFrame has each for for one article\n",
    "> * `nyt-articles-consolidated-exploded.csv`: Exploded DataFrame has as many rows for article as there are subfields inside keywords column (following concept of tidy data for future data exploration)\n",
    "\n",
    "### Context\n",
    "\n",
    "> The output of this notebook shall be used for the EDA and Feature Engineering of out Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import LOCAL_INTERIM_DATA_PATH\n",
    "from src.processing.IOController import consolidate_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consolidates and exports articles to DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Loading raw data into single DataFrame\"}\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4458/4458 [04:08<00:00, 17.97it/s]\n",
      "{\"message\": \"`df` sucessfully exported to c:\\\\users\\\\muril\\\\documents\\\\github\\\\newspapers-text-mining\\\\data\\\\interim\\\\nyt-articles-consolidated.csv\"}\n",
      "{\"message\": \"`exploded_df` sucessfully exported to c:\\\\users\\\\muril\\\\documents\\\\github\\\\newspapers-text-mining\\\\data\\\\interim\\\\nyt-articles-consolidated-exploded.csv\"}\n"
     ]
    }
   ],
   "source": [
    "df, exploded_df = consolidate_articles(prefix='nyt-articles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks shape of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21116, 21), (149637, 24))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, exploded_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks oldest and newest articles available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-28 00:04:15+0000', tz='UTC'),\n",
       " Timestamp('2020-07-20 23:43:50+0000', tz='UTC'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pub_date.min(), df.pub_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short sanity check to confirm if extracted data is correct. This analysis will be deepened on EDA notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Conclusion`: Data succesfully exported for proceeding to further notebooks since it corresponds to the expected date ranges (last 18 months) with a reasonable volume (21k articles = ca. 1.1 k / month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
